{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44a0ce3",
   "metadata": {},
   "source": [
    "### Querying Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "609d9dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pandas Series can be queried either by the index position or the index label.\n",
    "# To query by numeric location, starting at zero, use the iloc attribute. \n",
    "# To query by the index label, you can use the loc attribute.\n",
    "\n",
    "import pandas as pd\n",
    "students_classes = {'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adfa9a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the fourth entry in the series we would use the iloc attribute\n",
    "# with appropriate parameter\n",
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f7d0814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Physics'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query using index label we use loc attribute\n",
    "s.loc['Alice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4420caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that iloc and loc are not methods, they are attributes. So you don't use \n",
    "# parentheses to query them, but square brackets instead, which is called the indexing operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdd9c3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the indexing operator directly on the series itself.\n",
    "# Behaves like iloc attribute and makes code more readable.\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38d1fa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Physics'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we pass in an object/ index label it will behave as loc attribute\n",
    "s['Alice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0de3b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what happens if your index is a list of integers? This is a bit complicated and Pandas can't \n",
    "# determine automatically whether you're intending to query by index position or index label. So \n",
    "# you need to be careful when using the indexing operator on the Series itself. The safer option \n",
    "# is to be more explicit and use the iloc or loc attributes directly.\n",
    "\n",
    "class_code = {90: 'Physics',\n",
    "             100: 'Chemistry',\n",
    "             101: 'English',\n",
    "             102: 'History'}\n",
    "s = pd.Series(class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "557fd09d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a22686a3c819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# This will result in an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# If we try and call s[0] we get a key error because there's no item in the classes list with \n",
    "# an index of zero, instead we have to call iloc explicitly if we want the first item.\n",
    "\n",
    "# This will result in an error\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fd1a55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Physics'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using iloc attribute it will be more specific\n",
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb662b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# Iterate over a series in pandas\n",
    "# To find average score\n",
    "grades = pd.Series([60, 70, 80, 90])\n",
    "\n",
    "total = 0\n",
    "for grade in grades:\n",
    "    total += grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dfdf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works, but it's slow. Modern computers can do many tasks simultaneously, especially, \n",
    "# but not only, tasks involving mathematics.\n",
    "\n",
    "# Pandas and the underlying numpy libraries support a method of computation called vectorization. \n",
    "# Vectorization works with most of the functions in the numpy library, including the sum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5131777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# Here's how we would really write the code using the numpy sum method. First we need to import \n",
    "# the numpy module\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Then we just call np.sum and pass in an iterable item. In this case, our panda series.\n",
    "\n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65c31d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    904\n",
       "1    968\n",
       "2    584\n",
       "3    461\n",
       "4    136\n",
       "dtype: int32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a list of random integers\n",
    "numbers = pd.Series(np.random.randint(1, 1000, 10000))\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c112affa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify the length of th list\n",
    "len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7036621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ipython interpreter has something called magic functions begin with a percentage sign. \n",
    "# If we type this sign and then hit the Tab key,\n",
    "# you can see a list of the available magic functions. You could write your own magic functions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc263aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're actually going to use what's called a cellular magic function. These start with two \n",
    "# percentage signs and wrap the code in the current Jupyter cell. The function we're going to use \n",
    "# is called timeit. This function will run our code a few times to determine, on average, how long \n",
    "# it takes.\n",
    "\n",
    "# Let's run timeit with our original iterative code. You can give timeit the number of loops that \n",
    "# you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because \n",
    "# we're recording this. Note that in order to use a cellular magic function, it has to be the first \n",
    "# line in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "843193ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69 ms ± 650 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total += number\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "157182df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now trying it with vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3712b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 µs ± 55.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a08e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    904\n",
       "1    968\n",
       "2    584\n",
       "3    461\n",
       "4    136\n",
       "dtype: int32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Related feature in pandas and nummy is called broadcasting. With broadcasting, you can \n",
    "# apply an operation to every value in the series, changing the series. For instance, if we\n",
    "# wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
    "# directly on the Series object. \n",
    "\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "019d6c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    906\n",
       "1    970\n",
       "2    586\n",
       "3    463\n",
       "4    138\n",
       "dtype: int32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase everything in the series by 2\n",
    "numbers += 2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6230a752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    908\n",
       "1    972\n",
       "2    588\n",
       "3    465\n",
       "4    140\n",
       "dtype: int32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The procedural way of doing this would be to iterate through all of the items in the \n",
    "# series and increase the values directly. Pandas does support iterating through a series \n",
    "# much like a dictionary, allowing you to unpack values easily.\n",
    "\n",
    "# We can use the iteritems function which returns a label and value\n",
    "for label, value in numbers.iteritems():\n",
    "    # now for the item which is returned, lets call Series.at[]\n",
    "    # which allows access to a single value using label in a Series\n",
    "    numbers.at[label] = value+2\n",
    "# Check result of this computation\n",
    "numbers.head()\n",
    "\n",
    "# Earlies set_value was used instead of Series.at[] but was deprecated in later Python ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b58d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 ms ± 23.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# Comparing speeds between looping and broadcasting in pandas\n",
    "s = pd.Series(np.random.randint(1, 1000, 10000))\n",
    "for label, value in numbers.iteritems():\n",
    "    numbers.at[label] = value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6eaf0ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 µs ± 73.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(1, 1000, 10000))\n",
    "# Broadcast with +=\n",
    "s += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "076ef5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a note on using the indexing operators to access series data. The .loc attribute lets \n",
    "# you not only modify data in place, but also add new data as well. If the value you pass in as \n",
    "# the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
    "# While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
    "# change the underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7925ee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "English    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# Adding a value using .loc\n",
    "s.loc['English'] = 4\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4d1e521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following is an example where index values are not unique, and this makes\n",
    "# pandas Series a little different conceptually then, for instance, a relational database.\n",
    "\n",
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'})\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d86695ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Psychology\n",
       "Kelly           EVS\n",
       "Kelly     Chemistry\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Series just for some new student Kelly.\n",
    "kelly_classes = pd.Series(['Psychology', 'EVS', 'Chemistry'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5aec8b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Psychology\n",
       "Kelly           EVS\n",
       "Kelly     Chemistry\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can append all of the data in this new Series to the first using the .append() function.\n",
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41917fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a couple of important considerations when using append. First, Pandas will take \n",
    "# the series and try to infer the best data types to use. In this example, everything is a string, \n",
    "# so there's no problems here. Second, the append method doesn't actually change the underlying Series\n",
    "# objects, it instead returns a new series which is made up of the two appended together. This is\n",
    "# a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
    "# one you should come to expect. By printing the original series we can see that that series hasn't\n",
    "# changed.\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d2f7f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelly    Psychology\n",
       "Kelly           EVS\n",
       "Kelly     Chemistry\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we see that when we query the appended series for Kelly, we don't get a single value, \n",
    "# but a series itself. \n",
    "all_students_classes.loc['Kelly']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
